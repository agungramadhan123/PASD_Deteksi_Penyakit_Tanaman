{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Direktori dataset dan output\n",
    "dir_dataset = r\"C:\\Users\\User\\Desktop\\Projects\\PASD_Deteksi_Penyakit_Tanaman \\Dataset_Classification\"\n",
    "dir_output = r\"C:\\Users\\User\\Desktop\\Projects\\PASD_Deteksi_Penyakit_Tanaman \\Model\"\n",
    "model_name = f\"cnn-{time.strftime('%Y%m%d')}\"\n",
    "\n",
    "# Parameter pelatihan\n",
    "EPOCH = 1\n",
    "BATCH = 64\n",
    "WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformasi gambar untuk pelatihan dan validasi\n",
    "image_size = (224, 224)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, transform):\n",
    "    try:\n",
    "        return datasets.ImageFolder(root=path, transform=transform)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading dataset at {path}: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Dataset dan DataLoader\n",
    "train_dataset = load_dataset(os.path.join(dir_dataset, \"train_aug\"), train_transform)\n",
    "val_dataset = load_dataset(os.path.join(dir_dataset, \"val\"), val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=WORKER)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH, shuffle=False, num_workers=WORKER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
